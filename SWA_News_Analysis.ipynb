{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lzCfMrlSUpje"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W6vDxEwiWtn4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Stats\n",
    "\n",
    "# Misc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rqjzvtpkXoOY"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Dataset/train_file.csv')\n",
    "test = pd.read_csv('Dataset/test_file.csv')\n",
    "submission = pd.read_csv('Dataset/sample_submission.csv')\n",
    "test_id = test['IDLink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "sz9RO5LmXsCN",
    "outputId": "a088cf51-a027-43bf-a666-69e33771d741"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr3CMgRv1N</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wc81vGp8qZ</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zNGH03CrZH</td>\n",
       "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
       "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.425210</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3sM1H0W8ts</td>\n",
       "      <td>Finland GDP Expands In Q4</td>\n",
       "      <td>Finland's economy expanded marginally in the t...</td>\n",
       "      <td>RTT News</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:06:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wUbnxgvqaZ</td>\n",
       "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:11:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink                                              Title  \\\n",
       "0  Tr3CMgRv1N   Obama Lays Wreath at Arlington National Cemetery   \n",
       "1  Wc81vGp8qZ        A Look at the Health of the Chinese Economy   \n",
       "2  zNGH03CrZH   Nouriel Roubini: Global Economy Not Back to 2008   \n",
       "3  3sM1H0W8ts                          Finland GDP Expands In Q4   \n",
       "4  wUbnxgvqaZ  Tourism, govt spending buoys Thai economy in J...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...   \n",
       "1  Tim Haywood, investment director business-unit...   \n",
       "2  Nouriel Roubini, NYU professor and chairman at...   \n",
       "3  Finland's economy expanded marginally in the t...   \n",
       "4  Tourism and public spending continued to boost...   \n",
       "\n",
       "                                     Source    Topic          PublishDate  \\\n",
       "0                                 USA TODAY    obama  2002-04-02 00:00:00   \n",
       "1                                 Bloomberg  economy  2008-09-20 00:00:00   \n",
       "2                                 Bloomberg  economy  2012-01-28 00:00:00   \n",
       "3                                  RTT News  economy  2015-03-01 00:06:00   \n",
       "4  The Nation - Thailand&#39;s English news  economy  2015-03-01 00:11:00   \n",
       "\n",
       "   Facebook  GooglePlus  LinkedIn  SentimentTitle  SentimentHeadline  \n",
       "0        -1          -1        -1        0.000000          -0.053300  \n",
       "1        -1          -1        -1        0.208333          -0.156386  \n",
       "2        -1          -1        -1       -0.425210           0.139754  \n",
       "3        -1          -1        -1        0.000000           0.026064  \n",
       "4        -1          -1        -1        0.000000           0.141084  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rh_sideSXu-P",
    "outputId": "32c058f5-9f71-40ba-961d-e78c1e511780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55932 entries, 0 to 55931\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   IDLink             55932 non-null  object \n",
      " 1   Title              55932 non-null  object \n",
      " 2   Headline           55932 non-null  object \n",
      " 3   Source             55757 non-null  object \n",
      " 4   Topic              55932 non-null  object \n",
      " 5   PublishDate        55932 non-null  object \n",
      " 6   Facebook           55932 non-null  int64  \n",
      " 7   GooglePlus         55932 non-null  int64  \n",
      " 8   LinkedIn           55932 non-null  int64  \n",
      " 9   SentimentTitle     55932 non-null  float64\n",
      " 10  SentimentHeadline  55932 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "gJezE2baXxIy",
    "outputId": "8db6c8b2-6ab3-49a8-c098-a54104a16a8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55932.000000</td>\n",
       "      <td>55932.000000</td>\n",
       "      <td>55932.000000</td>\n",
       "      <td>55932.000000</td>\n",
       "      <td>55932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.050329</td>\n",
       "      <td>4.551616</td>\n",
       "      <td>14.300132</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>-0.029577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>722.931314</td>\n",
       "      <td>21.137177</td>\n",
       "      <td>76.651420</td>\n",
       "      <td>0.137569</td>\n",
       "      <td>0.143038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.838525</td>\n",
       "      <td>-0.755355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.079057</td>\n",
       "      <td>-0.116927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.027277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.063969</td>\n",
       "      <td>0.057354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49211.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>3716.000000</td>\n",
       "      <td>0.962354</td>\n",
       "      <td>0.964646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Facebook    GooglePlus      LinkedIn  SentimentTitle  \\\n",
       "count  55932.000000  55932.000000  55932.000000    55932.000000   \n",
       "mean     132.050329      4.551616     14.300132       -0.006318   \n",
       "std      722.931314     21.137177     76.651420        0.137569   \n",
       "min       -1.000000     -1.000000     -1.000000       -0.838525   \n",
       "25%        0.000000      0.000000      0.000000       -0.079057   \n",
       "50%        6.000000      0.000000      0.000000        0.000000   \n",
       "75%       37.000000      2.000000      4.000000        0.063969   \n",
       "max    49211.000000   1267.000000   3716.000000        0.962354   \n",
       "\n",
       "       SentimentHeadline  \n",
       "count       55932.000000  \n",
       "mean           -0.029577  \n",
       "std             0.143038  \n",
       "min            -0.755355  \n",
       "25%            -0.116927  \n",
       "50%            -0.027277  \n",
       "75%             0.057354  \n",
       "max             0.964646  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvCOGcJZXzpk",
    "outputId": "2faa81d0-aba9-4029-c86f-d2ad0ffbafd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink                 0\n",
       "Title                  0\n",
       "Headline               0\n",
       "Source               175\n",
       "Topic                  0\n",
       "PublishDate            0\n",
       "Facebook               0\n",
       "GooglePlus             0\n",
       "LinkedIn               0\n",
       "SentimentTitle         0\n",
       "SentimentHeadline      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQV-DW3sX1gW",
    "outputId": "3282e7b9-b253-4ce8-cc83-b3ebd581d127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink           0\n",
       "Title            0\n",
       "Headline         0\n",
       "Source         101\n",
       "Topic            0\n",
       "PublishDate      0\n",
       "Facebook         0\n",
       "GooglePlus       0\n",
       "LinkedIn         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeD3XrQ-X3T_",
    "outputId": "0c057b8f-0b8a-4f23-b221-a7efdae7f48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bloomberg           992\n",
       "Reuters             763\n",
       "ABC News            645\n",
       "New York Times      573\n",
       "The Guardian        551\n",
       "Business Insider    550\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Source'].value_counts()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d47gvMqVX6bL"
   },
   "outputs": [],
   "source": [
    "train['Source'] = train['Source'].fillna('Bloomberg')\n",
    "test['Source'] = test['Source'].fillna('Bloomberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bsg68-egX8dA",
    "outputId": "a80dcfb3-8dba-4ff6-87dd-ca9b9013268a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "  text_token = word_tokenize(text)\n",
    "  filtered_text = ' '.join([w.lower() for w in text_token if w.lower() not in stop and len(w) > 2])\n",
    "  filtered_text = filtered_text.replace(r\"[^a-zA-Z]+\", '')\n",
    "  text_only = re.sub(r'\\b\\d+\\b', '', filtered_text)\n",
    "  clean_text = text_only.replace(',', '').replace('.', '').replace(':', '')\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "z_WJ63WlX-0s"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'] = train['Title'] + ' ' + train['Source'] + ' ' + train['Topic']\n",
    "test['Text_Title'] = test['Title'] + ' ' + test['Source'] + ' ' + test['Topic']\n",
    "\n",
    "train['Text_Headline'] = train['Headline'] + ' ' + train['Source'] + ' ' + train['Topic']\n",
    "test['Text_Headline'] = test['Headline'] + ' ' + test['Source'] + ' ' + test['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wRTbg3kRYBjn",
    "outputId": "c355f86c-db95-4bd4-b9a4-0bf8143e0436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monday, 29 Feb 2016 Bloomberg palestine'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text_Title'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-AZKy72XYEAL"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'] = [clean(x) for x in train['Text_Title']]\n",
    "test['Text_Title'] = [clean(x) for x in test['Text_Title']]\n",
    "\n",
    "train['Text_Headline'] = [clean(x) for x in train['Text_Headline']]\n",
    "test['Text_Headline'] = [clean(x) for x in test['Text_Headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FO8k4n0UYGO2",
    "outputId": "e3383046-5ab8-4a9b-be3d-ff6a301a191e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\ntf.test.gpu_device_name()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pkiGQFSTYSyD",
    "outputId": "732e4248-48cf-46a9-dafa-cb7851b12b23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/device:GPU:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xWRnEMf-YVVv",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for ind, row in train.iterrows():\n",
    "    text += row[\"Text_Title\"] + \" \"\n",
    "text = text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qRGQoT-0YbWL",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for ind, row in train.iterrows():\n",
    "    text += row[\"Text_Headline\"] + \" \"\n",
    "text = text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0_yjSmaWYfM7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "train_v_Title = vectorizer.fit_transform(train['Text_Title'])\n",
    "test_v_Title = vectorizer.transform(test['Text_Title'])\n",
    "\n",
    "vectorizer_ = TfidfVectorizer()\n",
    "\n",
    "train_v_Headline = vectorizer_.fit_transform(train['Text_Headline'])\n",
    "test_v_Headline = vectorizer_.transform(test['Text_Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7uPa73WvYiS-",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['polarity_t'] = train['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test['polarity_t'] = test['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "train['subjectivity_t'] = train['Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "test['subjectivity_t'] = test['Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "06W8aisDYl22",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['polarity_h'] = train['Headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test['polarity_h'] = test['Headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "train['subjectivity_h'] = train['Headline'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "test['subjectivity_h'] = test['Headline'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Vs03vglaYtpb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "train['Topic'] = encoder.fit_transform(train['Topic'])\n",
    "test['Topic'] = encoder.transform(test['Topic'])\n",
    "\n",
    "total = train['Source'].to_list() + test['Source'].to_list()\n",
    "total = encoder.fit_transform(total)\n",
    "train['Source'] = encoder.transform(train['Source'])\n",
    "test['Source'] = encoder.transform(test['Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jXh2HaB_YuB4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_weekday = []\n",
    "test_weekday = []\n",
    "\n",
    "for i in train['PublishDate']:\n",
    "    train_weekday.append(datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\"))\n",
    "    \n",
    "for i in test['PublishDate']:\n",
    "    test_weekday.append(datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\").strftime(\"%A\"))\n",
    "\n",
    "train['weekday'] = train_weekday\n",
    "test['weekday'] = test_weekday\n",
    "\n",
    "\n",
    "# convert weekday to 0-6\n",
    "\n",
    "train['weekday'] = train['weekday'].map({'Monday': 0,\n",
    "                                        'Tuesday': 1,\n",
    "                                        'Wednesday': 2,\n",
    "                                        'Thursday': 3,\n",
    "                                        'Friday': 4,\n",
    "                                        'Saturday': 5,\n",
    "                                        'Sunday': 6})\n",
    "test['weekday'] = test['weekday'].map({'Monday': 0,\n",
    "                                        'Tuesday': 1,\n",
    "                                        'Wednesday': 2,\n",
    "                                        'Thursday': 3,\n",
    "                                        'Friday': 4,\n",
    "                                        'Saturday': 5,\n",
    "                                        'Sunday': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "o47GTZA9Yw43",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train[\"hour\"] = train[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])\n",
    "test[\"hour\"] = test[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xawMDtnUY0f8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Number of words in the Title \n",
    "train[\"num_words_t\"] = train[\"Text_Title\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words_t\"] = test[\"Text_Title\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of unique words in the Title \n",
    "train[\"num_unique_words_t\"] = train[\"Text_Title\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words_t\"] = test[\"Text_Title\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters in the Title \n",
    "train[\"num_chars_t\"] = train[\"Text_Title\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars_t\"] = test[\"Text_Title\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Average length of the words in the Title \n",
    "train[\"mean_word_len_t\"] = train[\"Text_Title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len_t\"] = test[\"Text_Title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ofNnB3LKY4DJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Number of words in the Headline \n",
    "train[\"num_words_h\"] = train[\"Text_Headline\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words_h\"] = test[\"Text_Headline\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of unique words in the Headline \n",
    "train[\"num_unique_words_h\"] = train[\"Text_Headline\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words_h\"] = test[\"Text_Headline\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters in the Headline \n",
    "train[\"num_chars_h\"] = train[\"Text_Headline\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars_h\"] = test[\"Text_Headline\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Average length of the words in the Headline \n",
    "train[\"mean_word_len_h\"] = train[\"Text_Headline\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len_h\"] = test[\"Text_Headline\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IVGzLSG_Y57V",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "cols = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_t', 'num_unique_words_t', 'num_chars_t', 'mean_word_len_t',\n",
    "        'num_words_h', 'num_unique_words_h', 'num_chars_h', 'mean_word_len_h', 'hour', 'weekday']\n",
    "\n",
    "for col in cols:\n",
    "  train[col] = scaler.fit_transform(train[col].values.reshape(-1, 1))\n",
    "  test[col] = scaler.transform(test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lFZNo9ZFY830",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols_t = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_t', 'num_unique_words_t', 'num_chars_t', 'mean_word_len_t', 'polarity_t', 'subjectivity_t', 'hour', 'weekday']\n",
    "train_X1 = train[cols_t]\n",
    "test_X1 = test[cols_t]\n",
    "\n",
    "cols_h = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_h', 'num_unique_words_h', 'num_chars_h', 'mean_word_len_h', 'polarity_h', 'subjectivity_h', 'hour', 'weekday']\n",
    "train_X2 = train[cols_h]\n",
    "test_X2 = test[cols_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H0cS0xA8Y-x6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_X_Title = hstack([train_v_Title, csr_matrix(train_X1.values)])\n",
    "test_X_Title = hstack([test_v_Title, csr_matrix(test_X1.values)])\n",
    "y1 = train['SentimentTitle']\n",
    "\n",
    "train_X_Headline = hstack([train_v_Headline, csr_matrix(train_X2.values)])\n",
    "test_X_Headline = hstack([test_v_Headline, csr_matrix(test_X2.values)])\n",
    "y2 = train['SentimentHeadline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bl7CSsxzZBwN",
    "outputId": "da2afbbd-752e-4bd3-f663-1decce8fe735",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9433379199351876\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Title, y1, test_size=0.20, random_state=42)\n",
    "\n",
    "clf1 = LinearSVR(C=0.2)\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "mae1 = mean_absolute_error(y_pred1, y_test)\n",
    "print('MAE:', 1 - mae1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NU8BH3PZEuu",
    "outputId": "92ac7c0f-9c9d-43fb-f313-386f0bdb41ef",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9291381949857027\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Headline, y2, test_size=0.20, random_state=42)\n",
    "\n",
    "clf2 = LinearSVR(C=0.1)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "mae2 = mean_absolute_error(y_pred2, y_test)\n",
    "print('MAE:', 1 - mae2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbLXrHEyZ_Vn"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "B_t5Q8XDZag4",
    "outputId": "8e4fd1d4-cf2e-4c86-f145-044820c835dc",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain = pd.read_csv('/content/train_file.csv')\\ntest = pd.read_csv('/content/test_file.csv')\\nsubmission = pd.read_csv('/content/sample_submission.csv')\\ntest_id = test['IDLink']\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train = pd.read_csv('/content/train_file.csv')\n",
    "test = pd.read_csv('/content/test_file.csv')\n",
    "submission = pd.read_csv('/content/sample_submission.csv')\n",
    "test_id = test['IDLink']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJbXb41Bh3VD"
   },
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNOGmnMfbm81",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CHVxb_F_iMGa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "L0-coUxuiVov",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.2 GiB for an array with shape (38797, 38797) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-c750ee722116>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mclfRidgeCV\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRidgeCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0malphas\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m1e-3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1e-2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1e-1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mclfRidgeCV\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1600\u001B[0m                                   \u001B[0mstore_cv_values\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstore_cv_values\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1601\u001B[0m                                   is_clf=is_classifier(self))\n\u001B[1;32m-> 1602\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1603\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malpha_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malpha_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1604\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_score_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_score_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1491\u001B[0m             \u001B[0msqrt_sw\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1492\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1493\u001B[1;33m         \u001B[0mX_mean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mdecomposition\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecompose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msqrt_sw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1494\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1495\u001B[0m         \u001B[0mscorer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_scoring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscoring\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_none\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001B[0m in \u001B[0;36m_eigen_decompose_covariance\u001B[1;34m(self, X, y, sqrt_sw)\u001B[0m\n\u001B[0;32m   1319\u001B[0m         \"\"\"\n\u001B[0;32m   1320\u001B[0m         \u001B[0mn_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1321\u001B[1;33m         \u001B[0mcov\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_features\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1322\u001B[0m         \u001B[0mcov\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_mean\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_covariance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msqrt_sw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1323\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_intercept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 11.2 GiB for an array with shape (38797, 38797) and data type float64"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clfRidge = Ridge(alpha=1.0)\n",
    "clfRidge.fit(X_train, y_train)\n",
    "\n",
    "clfLasso = Lasso(alpha=0.1)\n",
    "clfRidge.fit(X_train, y_train)\n",
    "\n",
    "clfRidgeCV = RidgeCV(alphas = [1e-3, 1e-2, 1e-1, 1])\n",
    "clfRidgeCV.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clfElasticNet = ElasticNet(random_state=42)\n",
    "clfElasticNet.fit(X_train, y_train)\n",
    "\n",
    "clfDT = DecisionTreeRegressor(random_state=42)\n",
    "clfDT.fit(X_train, y_train)\n",
    "\n",
    "clfKNN = KNeighborsRegressor(n_neighbors=2)\n",
    "clfKNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "head not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-54-73020798007e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mX_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, attr)\u001B[0m\n\u001B[0;32m    685\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetnnz\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    686\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 687\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattr\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\" not found\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    688\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    689\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: head not found"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfElasticNet = ElasticNet(random_state=42)\n",
    "clfElasticNet.fit(X_train, y_train)\n",
    "\n",
    "clfDT = DecisionTreeRegressor(random_state=42)\n",
    "clfDT.fit(X_train, y_train)\n",
    "\n",
    "clfKNN = KNeighborsRegressor(n_neighbors=2)\n",
    "clfKNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3wJcvVSkjE4W",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncat_columns = []\\n\\nfor col in train_df.select_dtypes('object').columns:\\n    print(col)\\n    cat_columns.append(col)\\n    le = LabelEncoder()\\n    train_df[col] = le.fit_transform(train_df[col])\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cat_columns = []\n",
    "\n",
    "for col in train_df.select_dtypes('object').columns:\n",
    "    print(col)\n",
    "    cat_columns.append(col)\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "cat_features_index = [i for i, col in enumerate(train_df.columns) if col in cat_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "NUM_OF_BOOST_ROUND = 10000\n",
    "EARLY_STOPPING = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfLasso.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clfLasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02996178, -0.02996178, -0.02996178, ..., -0.02996178,\n",
       "       -0.02996178, -0.02996178])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor, BaggingRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20598868017110838"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensGB = GradientBoostingRegressor(random_state=0)\n",
    "ensGB.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "('lr', clfRidge),\n",
    "('la', clfLasso),\n",
    "('en', clfElasticNet),\n",
    "('dt', clfDT),\n",
    "('knn', clfKNN),\n",
    "('svr', clf1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5236720228630106"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensST = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=clf )\n",
    "ensST.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37867756626623883"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensVR = VotingRegressor(estimators=estimators)\n",
    "ensVR.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-46-5e5d258d601d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mensBG\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBaggingRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[0mself\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m         \"\"\"\n\u001B[1;32m--> 243\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    244\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001B[0m\n\u001B[0;32m    378\u001B[0m                 \u001B[0mtotal_n_estimators\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m                 verbose=self.verbose)\n\u001B[1;32m--> 380\u001B[1;33m             for i in range(n_jobs))\n\u001B[0m\u001B[0;32m    381\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m         \u001B[1;31m# Reduce\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1040\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1041\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 263\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 263\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_parallel_build_estimators\u001B[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001B[0m\n\u001B[0;32m    108\u001B[0m                 \u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnot_indices_mask\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    390\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001B[1;32m--> 392\u001B[1;33m                 for i, t in enumerate(trees))\n\u001B[0m\u001B[0;32m    393\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    394\u001B[0m             \u001B[1;31m# Collect newly grown trees\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1052\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1054\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1055\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1056\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    931\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    932\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 933\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    934\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    935\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    428\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 430\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    431\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    294\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 296\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    297\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ensBG = BaggingRegressor(base_estimator=clf,n_estimators=10, random_state=0).fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-343897b62395>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-47-343897b62395>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    from sklearn.metrics import .\u001B[0m\n\u001B[1;37m                                ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, max_error\\\n",
    "                            ,mean_absolute_error\\\n",
    "                            ,mean_squared_error\\\n",
    "                            ,mean_squared_log_error\\\n",
    "                            ,median_absolute_error\\\n",
    "                            ,r2_score\\\n",
    "                            ,mean_poisson_deviance\\\n",
    "                            ,mean_gamma_deviance\n",
    "\n",
    "def regscore(algo):\n",
    "    y_pred = algo.predict(X_test)\n",
    "    \n",
    "    print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "    print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "    print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "    print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "    print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "    print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "    # print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "    print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "    print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24 in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==0.24) (1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==0.24) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==0.24) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==0.24) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.24 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST REGRESSION\n",
      "Explained Variance Score:  0.3754662992366208\n",
      "Explained Variance Score:  0.3754662992366208\n",
      "Max Error:  0.6453005986747211\n",
      "Mean Absolute Error:  0.08377584950377034\n",
      "Mean Squared Error:  0.012658294655291485\n",
      "Median Absolute Error:  0.06372603753444438\n",
      "R^2 Score:  0.3753906144232232\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "    # print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELASTIC NETS\n",
      "Explained Variance Score:  0.0\n",
      "Explained Variance Score:  0.0\n",
      "Max Error:  0.7695915826424073\n",
      "Mean Absolute Error:  0.10934995597314702\n",
      "Mean Squared Error:  0.020269633288537012\n",
      "Median Absolute Error:  0.08672417053070185\n",
      "R^2 Score:  -0.0001823736128021558\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfElasticNet.predict(X_test)\n",
    "print(\"ELASTIC NETS\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE REGRESSION\n",
      "Explained Variance Score:  0.5332691852163784\n",
      "Explained Variance Score:  0.5332691852163784\n",
      "Max Error:  0.720209323483589\n",
      "Mean Absolute Error:  0.07195100496698752\n",
      "Mean Squared Error:  0.009458765371788965\n",
      "Median Absolute Error:  0.05443684704128328\n",
      "R^2 Score:  0.533267806756395\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfRidge.predict(X_test)\n",
    "print(\"RIDGE REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO REGRESSION\n",
      "Explained Variance Score:  0.0\n",
      "Explained Variance Score:  0.0\n",
      "Max Error:  0.7695915826424073\n",
      "Mean Absolute Error:  0.10934995597314702\n",
      "Mean Squared Error:  0.020269633288537012\n",
      "Median Absolute Error:  0.08672417053070185\n",
      "R^2 Score:  -0.0001823736128021558\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfLasso.predict(X_test)\n",
    "print(\"LASSO REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREES REGRESSION\n",
      "Explained Variance Score:  -0.10490278644360518\n",
      "Explained Variance Score:  -0.10490278644360518\n",
      "Max Error:  0.8780334486914763\n",
      "Mean Absolute Error:  0.10978541114249249\n",
      "Mean Squared Error:  0.022394382040141395\n",
      "Median Absolute Error:  0.0841601971075437\n",
      "R^2 Score:  -0.10502572324124992\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfDT.predict(X_test)\n",
    "print(\"DECISION TREES REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NEIGHBOURS REGRESSION\n",
      "Explained Variance Score:  -0.2911120037621875\n",
      "Explained Variance Score:  -0.2911120037621875\n",
      "Max Error:  0.8237983217248042\n",
      "Mean Absolute Error:  0.12386549611926422\n",
      "Mean Squared Error:  0.026165784613515593\n",
      "Median Absolute Error:  0.09918820642960491\n",
      "R^2 Score:  -0.29112136315694825\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfKNN.predict(X_test)\n",
    "print(\"k-NEIGHBOURS REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-6434628a7a44>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclf1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"LINEAR REGRESSION\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Explained Variance Score: \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mexplained_variance_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Explained Variance Score: \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mexplained_variance_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Max Error: \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmax_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    234\u001B[0m         \u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    235\u001B[0m         \u001B[0mC\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 236\u001B[1;33m             \u001B[0mReturns\u001B[0m \u001B[0mpredicted\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    237\u001B[0m         \"\"\"\n\u001B[0;32m    238\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_decision_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36m_decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    218\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m         \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'csr'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'csc'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'coo'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    221\u001B[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001B[0;32m    222\u001B[0m                                dense_output=True) + self.intercept_\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m             warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n\u001B[0;32m     71\u001B[0m                           \u001B[1;34mf\"{version} passing these as positional arguments \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m                           \"will result in an error\", FutureWarning)\n\u001B[0m\u001B[0;32m     73\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001B[0m in \u001B[0;36msafe_sparse_dot\u001B[1;34m(a, b, dense_output)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m     if (sparse.issparse(a) and sparse.issparse(b)\n\u001B[0;32m    155\u001B[0m             and dense_output and hasattr(ret, \"toarray\")):\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001B[0m in \u001B[0;36m__matmul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    558\u001B[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001B[0;32m    559\u001B[0m                              \"use '*' instead\")\n\u001B[1;32m--> 560\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__mul__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    561\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__rmatmul__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001B[0m in \u001B[0;36m__mul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    496\u001B[0m             \u001B[1;31m# dense row or column vector\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'dimension mismatch'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    499\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mul_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "y_pred = clf1.predict(X_test)\n",
    "print(\"LINEAR REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSITNG REGRESSION\n",
      "Explained Variance Score:  0.20627282092625965\n",
      "Explained Variance Score:  0.20627282092625965\n",
      "Max Error:  0.6616571242142424\n",
      "Mean Absolute Error:  0.09745015573083572\n",
      "Mean Squared Error:  0.016091383636110207\n",
      "Median Absolute Error:  0.0787629524547549\n",
      "R^2 Score:  0.20598868017110838\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensGB.predict(X_test)\n",
    "print(\"GRADIENT BOOSITNG REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKING REGRESSION\n",
      "Explained Variance Score:  0.5237220647772931\n",
      "Explained Variance Score:  0.5237220647772931\n",
      "Max Error:  0.7580093829819871\n",
      "Mean Absolute Error:  0.07213162051756744\n",
      "Mean Squared Error:  0.009653232926673356\n",
      "Median Absolute Error:  0.05326959359890879\n",
      "R^2 Score:  0.5236720228630107\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensST.predict(X_test)\n",
    "print(\"STACKING REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOTING REGRESSION\n",
      "Explained Variance Score:  0.37867763534030185\n",
      "Explained Variance Score:  0.37867763534030185\n",
      "Max Error:  0.5788552566142677\n",
      "Mean Absolute Error:  0.0850450862359069\n",
      "Mean Squared Error:  0.012591681495279129\n",
      "Median Absolute Error:  0.06667888105086547\n",
      "R^2 Score:  0.37867756626623883\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensVR.predict(X_test)\n",
    "print(\"VOTING REGRESSION\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))\n",
    "# print(\"Mean Poisson Deviance: \",mean_poisson_deviance(y_test, y_pred))\n",
    "# print(\"Mean Gamma Deviance: \",mean_gamma_deviance(y_test, y_pred))\n",
    "# print(\"Mean Squared Log Error: \",mean_squared_log_error(y_test, y_pred))\n",
    "# print(\"Mean Absolute % Error: \",mean_absolute_percentage_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR SVR\n",
      "Explained Variance Score:  0.37867763534030185\n",
      "Explained Variance Score:  0.37867763534030185\n",
      "Max Error:  0.5788552566142677\n",
      "Mean Absolute Error:  0.0850450862359069\n",
      "Mean Squared Error:  0.012591681495279129\n",
      "Median Absolute Error:  0.06667888105086547\n",
      "R^2 Score:  0.37867756626623883\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = clf2.predict(X_test)\n",
    "print(\"LINEAR SVR\")\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Explained Variance Score: \",explained_variance_score(y_test, y_pred))\n",
    "print(\"Max Error: \",max_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error: \",mean_squared_error(y_test, y_pred))\n",
    "print(\"Median Absolute Error: \",median_absolute_error(y_test, y_pred))\n",
    "print(\"R^2 Score: \",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SWA_News Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}